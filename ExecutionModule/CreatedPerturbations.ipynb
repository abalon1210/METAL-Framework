{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4803da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/a1232953/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/a1232953/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/a1232953/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import google.generativeai as palm\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4681b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "palm.configure(api_key='YOUR_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b13d4872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/text-bison-001\n"
     ]
    }
   ],
   "source": [
    "models = [m for m in palm.list_models() if 'generateText' in m.supported_generation_methods]\n",
    "model = models[0].name\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c99d14",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c44fada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def talktomodel(prompt):\n",
    "    completion = palm.generate_text(\n",
    "    model=model,\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    # The maximum length of the response\n",
    "    max_output_tokens=800,\n",
    "    )\n",
    "\n",
    "    return(completion.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c20e011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_csv(i, task, inputID, inputText, pertMethod, pertText, origOut, pertOut, origTime, pertTime):\n",
    "    csvName = 'CreatedFunctions_Iteration' + str(i) + '_' + task + '_PaLMAPI.csv'\n",
    "    \n",
    "    if not os.path.isfile(csvName) or os.path.getsize(csvName) == 0:\n",
    "        with open(csvName, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "            writer.writerow(['InputTextID', 'InputText', 'PerturbationID', 'PerturbedText', 'OriginalOutput', 'PerturbedOutput', 'OriginalTime', 'PerturbedTime'])\n",
    "    \n",
    "    with open(csvName, 'a', newline='', encoding='utf-8') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow([inputID, inputText, pertMethod, pertText, origOut, pertOut, origTime, pertTime])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "47543034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def introduce_typos(input_string): #character-level\n",
    "    typo_probability = 0.1\n",
    "    typoed_string = \"\"\n",
    "    for char in input_string:\n",
    "        if random.uniform(0, 1) < typo_probability:\n",
    "            typoed_string += chr(random.randint(97, 122))#random lowercase character\n",
    "        else:\n",
    "            typoed_string += char\n",
    "    return typoed_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "27d8ae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_characters(input_text): #character-level\n",
    "    deletion_probability = 0.1\n",
    "    deleted_text = ''\n",
    "    for char in input_text:\n",
    "        if random.uniform(0, 1) >= deletion_probability:\n",
    "            deleted_text += char\n",
    "    return deleted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3fde74fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_characters(input_text): #character-level\n",
    "    shuffle_probability = 0.1\n",
    "    words = input_text.split()\n",
    "    new_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        if len(word) <= 3 or random.uniform(0, 1) > shuffle_probability:\n",
    "            new_words.append(word)\n",
    "        else:\n",
    "            first_char = word[0]\n",
    "            last_char = word[-1]\n",
    "            middle_chars = list(word[1:-1])\n",
    "            random.shuffle(middle_chars)\n",
    "            shuffled_word = first_char + ''.join(middle_chars) + last_char\n",
    "            new_words.append(shuffled_word)\n",
    "            \n",
    "    return ' '.join(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4c6c2ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_characters(input_string): #character-level\n",
    "    typo_probability = 0.1\n",
    "    typoed_string = \"\"\n",
    "    for char in input_string:\n",
    "        if random.uniform(0, 1) < typo_probability:\n",
    "            typoed_string += chr(random.randint(97, 122))\n",
    "            typoed_string += char\n",
    "        else:\n",
    "            typoed_string += char\n",
    "    return typoed_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7cee512d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_leet(input_string): #character-level\n",
    "    \n",
    "    leet_mapping = {\n",
    "        'a': '4',\n",
    "        'e': '3',\n",
    "        'i': '1',\n",
    "        'o': '0'\n",
    "    }\n",
    "    leet_words = []\n",
    "    \n",
    "    leet_probability = 0.2\n",
    "    \n",
    "    words = input_string.split()\n",
    "    for word in words:\n",
    "        if random.uniform(0, 1) < leet_probability:\n",
    "            leet_text = ''\n",
    "            for char in word:\n",
    "                lowercase_char = char.lower()\n",
    "                if lowercase_char in leet_mapping:\n",
    "                    leet_text += leet_mapping[lowercase_char]\n",
    "                else:\n",
    "                    leet_text += char\n",
    "                    \n",
    "            leet_words.append(leet_text)\n",
    "            \n",
    "        else:\n",
    "            leet_words.append(word)\n",
    "            \n",
    "    return ' '.join(leet_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b088f779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_spaces(input_string): #character-level\n",
    "    space_probability = 0.3\n",
    "    spaced_string = \"\"\n",
    "    for char in input_string:\n",
    "        if random.uniform(0, 1) < space_probability:\n",
    "            spaced_string += ' '\n",
    "            spaced_string += char\n",
    "        else:\n",
    "            spaced_string += char\n",
    "    return spaced_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d655db50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_words(input_text): #word-level\n",
    "    new_word_probability = 0.2\n",
    "    random_words = [\"apple\", \"grape\", \"banana\", \"pear\"]\n",
    "    words = input_text.split()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if random.uniform(0, 1) < new_word_probability:\n",
    "            new_words.append(word)\n",
    "            new_words.append(random.choice(random_words))\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return ' '.join(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a1bb7981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_characters(input_text): #character-level\n",
    "    swap_probability = 0.2\n",
    "    words = input_text.split()\n",
    "    new_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        if len(word) <= 3 or random.uniform(0, 1) > swap_probability:\n",
    "            new_words.append(word)\n",
    "        else:\n",
    "            first_char = word[0]\n",
    "            last_char = word[-1]\n",
    "            middle_chars = list(word[1:-1])\n",
    "            char_no = range(len(middle_chars))\n",
    "            c1, c2 = random.sample(char_no, 2)\n",
    "            middle_chars[c1], middle_chars[c2] = middle_chars[c2], middle_chars[c1]\n",
    "            swapped_word = first_char + ''.join(middle_chars) + last_char\n",
    "            new_words.append(swapped_word)\n",
    "            \n",
    "    return ' '.join(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "57ebe9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def antonym_replacement(input_text): #word-level\n",
    "    words = input_text.split()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        antonyms = []\n",
    "        for syn in wordnet.synsets(word):\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.antonyms():\n",
    "                    antonyms.append(lemma.antonyms()[0].name())\n",
    "        if antonyms:\n",
    "            new_word = random.choice(antonyms)\n",
    "            new_words.append(new_word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return ' '.join(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7bd6669c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synonym_replacement(input_text): #word-level\n",
    "    words = input_text.split()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        synonyms = []\n",
    "        for syn in wordnet.synsets(word):\n",
    "            for lemma in syn.lemmas():\n",
    "                synonyms.append(lemma.name())\n",
    "        if synonyms:\n",
    "            new_words.append(random.choice(synonyms))\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return ' '.join(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0471aa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_random_sentence(input_text): #sentence-level\n",
    "    random_sentences = [\"Lorem ipsum dolor sit amet.\", \"Sit modi ipsam quo illum commodi et quia quisquam.\", \"Aut illo quibusdam sed voluptatum perspiciatis ut minus obcaecati.\"]\n",
    "    sentences = sent_tokenize(input_text)\n",
    "\n",
    "    for i in range(1,4):\n",
    "        sent_index = random.randint(0, len(sentences) - 1)\n",
    "        random_sentence = random.choice(random_sentences)\n",
    "        sentences[sent_index] = random_sentence\n",
    "\n",
    "    return ' '.join(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "400b0cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_random_sentence(input_text): #sentence-level\n",
    "    sentences = sent_tokenize(input_text)\n",
    "\n",
    "    for i in range(1,4):\n",
    "        sent_index = random.randint(0, len(sentences) - 1)\n",
    "        del sentences[sent_index]\n",
    "\n",
    "    return ' '.join(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "74ba45ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_mapping = {\n",
    "    \"sentiment analysis\": \"Analyse the sentiment of this text as positive, negative or neutral.\",\n",
    "    \"text summarization\": \"Summarize this text in five sentences\",\n",
    "    \"information retrieval\": \"List the top 10 information from this text.\",\n",
    "    \"toxicity detection\": \"Check whether this text contains toxic or spam content and say yes, no or unknown. Also provide reasons.\",\n",
    "    \"news classification\": \"Categorize the news text into the following categories: World, Sports, Business, Science/Technology.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "df3c4a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(row, iteration):\n",
    "    # add_to_csv(iteration, task, inputID, inputText, pertMethod, pertText, origOut, pertOut, origTime, pertTime)\n",
    "    task = row['task']\n",
    "    input_text = row['input']\n",
    "    inputID = row['inputID']\n",
    "    \n",
    "    if task in prompt_mapping:\n",
    "        \n",
    "        if task == \"sentiment analysis\" or task == \"toxicity detection\" or task == \"news classification\":\n",
    "            prompt = prompt_mapping[task]\n",
    "            \n",
    "            orig_new_text = input_text + \" \" + prompt\n",
    "            start_time = time.time()\n",
    "            origOut = talktomodel(orig_new_text)\n",
    "            end_time = time.time()\n",
    "            origTime = end_time - start_time\n",
    "        \n",
    "            perturbed_text = introduce_typos(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Introducing Typos\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "        \n",
    "            perturbed_text = delete_characters(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Deleting Characters\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "        \n",
    "            perturbed_text = synonym_replacement(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Replacing Synonyms\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "        \n",
    "            perturbed_text = add_words(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Adding random words\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "            \n",
    "            perturbed_text = to_leet(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Converting to l33t format\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "            \n",
    "            perturbed_text = shuffle_characters(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Shuffling characters in each word\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "            \n",
    "            perturbed_text = add_spaces(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Adding spaces in text\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "            \n",
    "            perturbed_text = add_characters(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Adding random characters\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "            \n",
    "            perturbed_text = swap_characters(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Swapping two random characters in each word\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "            \n",
    "            perturbed_text = antonym_replacement(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Replacing words with their antonyms\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "            \n",
    "        elif task == \"text summarization\" or task == \"information retrieval\":\n",
    "            prompt = prompt_mapping[task]\n",
    "            \n",
    "            orig_new_text = input_text + \" \" + prompt\n",
    "            start_time = time.time()\n",
    "            origOut = talktomodel(orig_new_text)\n",
    "            end_time = time.time()\n",
    "            origTime = end_time - start_time\n",
    "        \n",
    "            perturbed_text = introduce_typos(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Introducing Typos\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "        \n",
    "            perturbed_text = delete_characters(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Deleting Characters\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "        \n",
    "            perturbed_text = synonym_replacement(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Replacing Synonyms\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "        \n",
    "            perturbed_text = add_words(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Adding random words\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "     \n",
    "            perturbed_text = replace_random_sentence(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Replacing random sentences\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "            \n",
    "            perturbed_text = remove_random_sentence(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Removing random sentences\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "            \n",
    "            perturbed_text = to_leet(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Converting to l33t format\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "            \n",
    "            perturbed_text = add_characters(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Adding random characters\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "            \n",
    "            perturbed_text = antonym_replacement(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Replacing words with their antonyms\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "            \n",
    "            perturbed_text = shuffle_characters(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Shuffling characters in each word\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "            \n",
    "    else:\n",
    "        # task = question answering\n",
    "        orig_new_text = input_text\n",
    "        start_time = time.time()\n",
    "        origOut = talktomodel(orig_new_text)\n",
    "        end_time = time.time()\n",
    "        origTime = end_time - start_time\n",
    "        \n",
    "        pert_new_text = introduce_typos(input_text)\n",
    "        # print(pert_new_text)\n",
    "        pertMethod = \"Introducing Typos\"\n",
    "        start_time = time.time()\n",
    "        pertOut = talktomodel(pert_new_text)\n",
    "        end_time = time.time()\n",
    "        pertTime = end_time - start_time\n",
    "        add_to_csv(iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "        \n",
    "        pert_new_text = delete_characters(input_text)\n",
    "        pertMethod = \"Deleting Characters\"\n",
    "        start_time = time.time()\n",
    "        pertOut = talktomodel(pert_new_text)\n",
    "        end_time = time.time()\n",
    "        pertTime = end_time - start_time\n",
    "        add_to_csv(iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "        \n",
    "        pert_new_text = synonym_replacement(input_text)\n",
    "        pertMethod = \"Replacing Synonyms\"\n",
    "        start_time = time.time()\n",
    "        pertOut = talktomodel(pert_new_text)\n",
    "        end_time = time.time()\n",
    "        pertTime = end_time - start_time\n",
    "        add_to_csv(iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "        \n",
    "        pert_new_text = add_words(input_text)\n",
    "        pertMethod = \"Adding random words\"\n",
    "        start_time = time.time()\n",
    "        pertOut = talktomodel(pert_new_text)\n",
    "        end_time = time.time()\n",
    "        pertTime = end_time - start_time\n",
    "        add_to_csv(iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "        \n",
    "        pert_new_text = to_leet(input_text)\n",
    "        pertMethod = \"Converting to l33t format\"\n",
    "        start_time = time.time()\n",
    "        pertOut = talktomodel(pert_new_text)\n",
    "        end_time = time.time()\n",
    "        pertTime = end_time - start_time\n",
    "        add_to_csv(iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "            \n",
    "        pert_new_text = shuffle_characters(input_text)\n",
    "        pertMethod = \"Shuffling characters in each word\"\n",
    "        start_time = time.time()\n",
    "        pertOut = talktomodel(pert_new_text)\n",
    "        end_time = time.time()\n",
    "        pertTime = end_time - start_time\n",
    "        add_to_csv(iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "            \n",
    "        pert_new_text = add_spaces(input_text)\n",
    "        pertMethod = \"Adding spaces in text\"\n",
    "        start_time = time.time()\n",
    "        pertOut = talktomodel(pert_new_text)\n",
    "        end_time = time.time()\n",
    "        pertTime = end_time - start_time\n",
    "        add_to_csv(iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "            \n",
    "        pert_new_text = add_characters(input_text)\n",
    "        pertMethod = \"Adding random characters\"\n",
    "        start_time = time.time()\n",
    "        pertOut = talktomodel(pert_new_text)\n",
    "        end_time = time.time()\n",
    "        pertTime = end_time - start_time\n",
    "        add_to_csv(iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "            \n",
    "        pert_new_text = swap_characters(input_text)\n",
    "        pertMethod = \"Swapping two random characters in each word\"\n",
    "        start_time = time.time()\n",
    "        pertOut = talktomodel(pert_new_text)\n",
    "        end_time = time.time()\n",
    "        pertTime = end_time - start_time\n",
    "        add_to_csv(iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "            \n",
    "        pert_new_text = antonym_replacement(input_text)\n",
    "        pertMethod = \"Replacing words with their antonyms\"\n",
    "        start_time = time.time()\n",
    "        pertOut = talktomodel(pert_new_text)\n",
    "        end_time = time.time()\n",
    "        pertTime = end_time - start_time\n",
    "        add_to_csv(iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "802e92ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    csv_file_path = './ExecutionModule/InputsByTask/ir_inputs.csv'  \n",
    "    df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    for i in range(10,11):\n",
    "        for index, row in df.iterrows():\n",
    "            if i == 10 and index <= 88:\n",
    "                continue\n",
    "            print(i, index)\n",
    "            process_row(row,i)\n",
    "            time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f1b59a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 89\n",
      "10 90\n",
      "10 91\n",
      "10 92\n",
      "10 93\n",
      "10 94\n",
      "10 95\n",
      "10 96\n",
      "10 97\n",
      "10 98\n",
      "10 99\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
