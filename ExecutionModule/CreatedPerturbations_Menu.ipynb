{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4803da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/navi/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "[nltk_data] Downloading package wordnet to /Users/navi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/navi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/navi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import google.generativeai as palm\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import subprocess\n",
    "from itertools import product\n",
    "from datetime import datetime\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a4681b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "palm.configure(api_key='YOUR_GOOGLEPALM_KEY_HERE')\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=\"YOUR_OPENAI_KEY_HERE\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b13d4872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/text-bison-001\n"
     ]
    }
   ],
   "source": [
    "models = [m for m in palm.list_models() if 'generateText' in m.supported_generation_methods]\n",
    "model = models[0].name\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c44fada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def talktomodel(prompt, modelName):\n",
    "\n",
    "    if modelName == \"LLaMa2\":\n",
    "        args = (\"../../llama.cpp/main\", \"-m\", \"../../llama.cpp/models/llama2-7b-chat/llama-2-7b-chat.Q4_0.gguf\", \"-p\", prompt, \"-n\", \"2048\")\n",
    "\n",
    "        temp = subprocess.Popen(args, stdout = subprocess.PIPE)\n",
    "        output = str(temp.communicate())\n",
    "\n",
    "        return output\n",
    "\n",
    "    elif modelName == \"ChatGPT\":\n",
    "        completion = client.chat.completions.create(model=\"gpt-3.5-turbo\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "\n",
    "        return completion.choices[0].message.content\n",
    "        \n",
    "    else:\n",
    "        completion = palm.generate_text(\n",
    "        model=model,\n",
    "        prompt=prompt,\n",
    "        temperature=0,\n",
    "        # The maximum length of the response\n",
    "        max_output_tokens=800,\n",
    "        )\n",
    "\n",
    "        return(completion.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c20e011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_csv(model, qa, i, task, inputID, inputText, pertMethod, pertText, origOut, pertOut, origTime, pertTime):\n",
    "    csvName = 'CreatedFunctions_' + qa + '_Iteration' + str(i) + '_' + task + '_' + model + '.csv'\n",
    "    \n",
    "    if not os.path.isfile(csvName) or os.path.getsize(csvName) == 0:\n",
    "        with open(csvName, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "            writer.writerow(['InputTextID', 'InputText', 'PerturbationID', 'PerturbedText', 'OriginalOutput', 'PerturbedOutput', 'OriginalTime', 'PerturbedTime'])\n",
    "    \n",
    "    with open(csvName, 'a', newline='', encoding='utf-8') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow([inputID, inputText, pertMethod, pertText, origOut, pertOut, origTime, pertTime])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47543034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def introduce_typos(input_string): #character-level\n",
    "    typo_probability = 0.1\n",
    "    typoed_string = \"\"\n",
    "    for char in input_string:\n",
    "        if random.uniform(0, 1) < typo_probability:\n",
    "            typoed_string += chr(random.randint(97, 122))#random lowercase character\n",
    "        else:\n",
    "            typoed_string += char\n",
    "    return typoed_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27d8ae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_characters(input_text): #character-level\n",
    "    deletion_probability = 0.1\n",
    "    deleted_text = ''\n",
    "    for char in input_text:\n",
    "        if random.uniform(0, 1) >= deletion_probability:\n",
    "            deleted_text += char\n",
    "    return deleted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fde74fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_characters(input_text): #character-level\n",
    "    shuffle_probability = 0.1\n",
    "    words = input_text.split()\n",
    "    new_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        if len(word) <= 3 or random.uniform(0, 1) > shuffle_probability:\n",
    "            new_words.append(word)\n",
    "        else:\n",
    "            first_char = word[0]\n",
    "            last_char = word[-1]\n",
    "            middle_chars = list(word[1:-1])\n",
    "            random.shuffle(middle_chars)\n",
    "            shuffled_word = first_char + ''.join(middle_chars) + last_char\n",
    "            new_words.append(shuffled_word)\n",
    "            \n",
    "    return ' '.join(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c6c2ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_characters(input_string): #character-level\n",
    "    typo_probability = 0.1\n",
    "    typoed_string = \"\"\n",
    "    for char in input_string:\n",
    "        if random.uniform(0, 1) < typo_probability:\n",
    "            typoed_string += chr(random.randint(97, 122))\n",
    "            typoed_string += char\n",
    "        else:\n",
    "            typoed_string += char\n",
    "    return typoed_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cee512d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_leet(input_string): #character-level\n",
    "    \n",
    "    leet_mapping = {\n",
    "        'a': '4',\n",
    "        'e': '3',\n",
    "        'i': '1',\n",
    "        'o': '0'\n",
    "    }\n",
    "    leet_words = []\n",
    "    \n",
    "    leet_probability = 0.2\n",
    "    \n",
    "    words = input_string.split()\n",
    "    for word in words:\n",
    "        if random.uniform(0, 1) < leet_probability:\n",
    "            leet_text = ''\n",
    "            for char in word:\n",
    "                lowercase_char = char.lower()\n",
    "                if lowercase_char in leet_mapping:\n",
    "                    leet_text += leet_mapping[lowercase_char]\n",
    "                else:\n",
    "                    leet_text += char\n",
    "                    \n",
    "            leet_words.append(leet_text)\n",
    "            \n",
    "        else:\n",
    "            leet_words.append(word)\n",
    "            \n",
    "    return ' '.join(leet_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b088f779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_spaces(input_string): #character-level\n",
    "    space_probability = 0.3\n",
    "    spaced_string = \"\"\n",
    "    for char in input_string:\n",
    "        if random.uniform(0, 1) < space_probability:\n",
    "            spaced_string += ' '\n",
    "            spaced_string += char\n",
    "        else:\n",
    "            spaced_string += char\n",
    "    return spaced_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d655db50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_words(input_text): #word-level\n",
    "    new_word_probability = 0.2\n",
    "    random_words = [\"apple\", \"grape\", \"banana\", \"pear\"]\n",
    "    words = input_text.split()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if random.uniform(0, 1) < new_word_probability:\n",
    "            new_words.append(word)\n",
    "            new_words.append(random.choice(random_words))\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return ' '.join(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1bb7981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_characters(input_text): #character-level\n",
    "    swap_probability = 0.2\n",
    "    words = input_text.split()\n",
    "    new_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        if len(word) <= 3 or random.uniform(0, 1) > swap_probability:\n",
    "            new_words.append(word)\n",
    "        else:\n",
    "            first_char = word[0]\n",
    "            last_char = word[-1]\n",
    "            middle_chars = list(word[1:-1])\n",
    "            char_no = range(len(middle_chars))\n",
    "            c1, c2 = random.sample(char_no, 2)\n",
    "            middle_chars[c1], middle_chars[c2] = middle_chars[c2], middle_chars[c1]\n",
    "            swapped_word = first_char + ''.join(middle_chars) + last_char\n",
    "            new_words.append(swapped_word)\n",
    "            \n",
    "    return ' '.join(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57ebe9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def antonym_replacement(input_text): #word-level\n",
    "    words = input_text.split()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        antonyms = []\n",
    "        for syn in wordnet.synsets(word):\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.antonyms():\n",
    "                    antonyms.append(lemma.antonyms()[0].name())\n",
    "        if antonyms:\n",
    "            new_word = random.choice(antonyms)\n",
    "            new_words.append(new_word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return ' '.join(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bd6669c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synonym_replacement(input_text): #word-level\n",
    "    words = input_text.split()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        synonyms = []\n",
    "        for syn in wordnet.synsets(word):\n",
    "            for lemma in syn.lemmas():\n",
    "                synonyms.append(lemma.name())\n",
    "        if synonyms:\n",
    "            new_words.append(random.choice(synonyms))\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return ' '.join(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0471aa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_random_sentence(input_text): #sentence-level\n",
    "    random_sentences = [\"Lorem ipsum dolor sit amet.\", \"Sit modi ipsam quo illum commodi et quia quisquam.\", \"Aut illo quibusdam sed voluptatum perspiciatis ut minus obcaecati.\"]\n",
    "    sentences = sent_tokenize(input_text)\n",
    "\n",
    "    for i in range(1,4):\n",
    "        sent_index = random.randint(0, len(sentences) - 1)\n",
    "        random_sentence = random.choice(random_sentences)\n",
    "        sentences[sent_index] = random_sentence\n",
    "\n",
    "    return ' '.join(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "400b0cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_random_sentence(input_text): #sentence-level\n",
    "    sentences = sent_tokenize(input_text)\n",
    "\n",
    "    for i in range(1,4):\n",
    "        sent_index = random.randint(0, len(sentences) - 1)\n",
    "        del sentences[sent_index]\n",
    "\n",
    "    return ' '.join(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74ba45ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_mapping = {\n",
    "    \"sentiment analysis\": \"Analyse the sentiment of this text as positive, negative or neutral.\",\n",
    "    \"text summarization\": \"Summarize this text in five sentences\",\n",
    "    \"information retrieval\": \"List the top 10 information from this text.\",\n",
    "    \"toxicity detection\": \"Check whether this text contains toxic or spam content and say yes, no or unknown. Also provide reasons.\",\n",
    "    \"news classification\": \"Categorize the news text into the following categories: World, Sports, Business, Science/Technology.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df3c4a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(row, iteration, model, qa):\n",
    "    # add_to_csv(iteration, task, inputID, inputText, pertMethod, pertText, origOut, pertOut, origTime, pertTime)\n",
    "    task = row['task']\n",
    "    input_text = row['input']\n",
    "    inputID = row['inputID']\n",
    "    \n",
    "    if task in prompt_mapping:\n",
    "        \n",
    "        if task == \"sentiment analysis\" or task == \"toxicity detection\" or task == \"news classification\":\n",
    "            prompt = prompt_mapping[task]\n",
    "            \n",
    "            orig_new_text = input_text + \" \" + prompt\n",
    "            start_time = time.time()\n",
    "            origOut = talktomodel(orig_new_text, model)\n",
    "            end_time = time.time()\n",
    "            origTime = end_time - start_time\n",
    "        \n",
    "            perturbed_text = introduce_typos(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Introducing Typos\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text, model)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(model, qa, iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "        \n",
    "            perturbed_text = delete_characters(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Deleting Characters\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text, model)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(model, qa, iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "        \n",
    "            perturbed_text = synonym_replacement(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Replacing Synonyms\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text, model)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(model, qa, iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "        \n",
    "            perturbed_text = add_words(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Adding random words\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text, model)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(model, qa, iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "            \n",
    "            perturbed_text = to_leet(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Converting to l33t format\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text, model)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(model, qa, iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "            \n",
    "            perturbed_text = shuffle_characters(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Shuffling characters in each word\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text, model)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(model, qa, iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "            \n",
    "            perturbed_text = add_spaces(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Adding spaces in text\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text, model)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(model, qa, iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "            \n",
    "            perturbed_text = add_characters(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Adding random characters\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text, model)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(model, qa, iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "            \n",
    "            perturbed_text = swap_characters(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Swapping two random characters in each word\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text, model)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(model, qa, iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "            \n",
    "            perturbed_text = antonym_replacement(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Replacing words with their antonyms\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text, model)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(model, qa, iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "            \n",
    "        elif task == \"text summarization\" or task == \"information retrieval\":\n",
    "            prompt = prompt_mapping[task]\n",
    "            \n",
    "            orig_new_text = input_text + \" \" + prompt\n",
    "            start_time = time.time()\n",
    "            origOut = talktomodel(orig_new_text, model)\n",
    "            end_time = time.time()\n",
    "            origTime = end_time - start_time\n",
    "        \n",
    "            perturbed_text = introduce_typos(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Introducing Typos\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text, model)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(model, qa, iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "        \n",
    "            perturbed_text = delete_characters(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Deleting Characters\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text, model)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(model, qa, iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "        \n",
    "            perturbed_text = synonym_replacement(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Replacing Synonyms\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text, model)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(model, qa, iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "        \n",
    "            perturbed_text = add_words(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Adding random words\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text, model)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(model, qa, iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "     \n",
    "            perturbed_text = replace_random_sentence(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Replacing random sentences\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text, model)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(model, qa, iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "            \n",
    "            perturbed_text = remove_random_sentence(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Removing random sentences\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text, model)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(model, qa, iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "            \n",
    "            perturbed_text = to_leet(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Converting to l33t format\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text, model)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(model, qa, iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "            \n",
    "            perturbed_text = add_characters(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Adding random characters\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text, model)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(model, qa, iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "            \n",
    "            perturbed_text = antonym_replacement(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Replacing words with their antonyms\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text, model)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(model, qa, iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "            \n",
    "            perturbed_text = shuffle_characters(input_text)\n",
    "            pert_new_text = perturbed_text + \" \" + prompt\n",
    "            pertMethod = \"Shuffling characters in each word\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text, model)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(model, qa, iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "            \n",
    "    else:\n",
    "        # task = question answering\n",
    "        orig_new_text = input_text\n",
    "        start_time = time.time()\n",
    "        origOut = talktomodel(orig_new_text, model)\n",
    "        end_time = time.time()\n",
    "        origTime = end_time - start_time\n",
    "        \n",
    "        pert_new_text = introduce_typos(input_text)\n",
    "        # print(pert_new_text)\n",
    "        pertMethod = \"Introducing Typos\"\n",
    "        start_time = time.time()\n",
    "        pertOut = talktomodel(pert_new_text, model)\n",
    "        end_time = time.time()\n",
    "        pertTime = end_time - start_time\n",
    "        add_to_csv(model, qa, iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "        \n",
    "        pert_new_text = delete_characters(input_text)\n",
    "        pertMethod = \"Deleting Characters\"\n",
    "        start_time = time.time()\n",
    "        pertOut = talktomodel(pert_new_text, model)\n",
    "        end_time = time.time()\n",
    "        pertTime = end_time - start_time\n",
    "        add_to_csv(model, qa, iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "        \n",
    "        pert_new_text = synonym_replacement(input_text)\n",
    "        pertMethod = \"Replacing Synonyms\"\n",
    "        start_time = time.time()\n",
    "        pertOut = talktomodel(pert_new_text, model)\n",
    "        end_time = time.time()\n",
    "        pertTime = end_time - start_time\n",
    "        add_to_csv(model, qa, iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "        \n",
    "        pert_new_text = add_words(input_text)\n",
    "        pertMethod = \"Adding random words\"\n",
    "        start_time = time.time()\n",
    "        pertOut = talktomodel(pert_new_text, model)\n",
    "        end_time = time.time()\n",
    "        pertTime = end_time - start_time\n",
    "        add_to_csv(model, qa, iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "        \n",
    "        pert_new_text = to_leet(input_text)\n",
    "        pertMethod = \"Converting to l33t format\"\n",
    "        start_time = time.time()\n",
    "        pertOut = talktomodel(pert_new_text, model)\n",
    "        end_time = time.time()\n",
    "        pertTime = end_time - start_time\n",
    "        add_to_csv(model, qa, iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "            \n",
    "        pert_new_text = shuffle_characters(input_text)\n",
    "        pertMethod = \"Shuffling characters in each word\"\n",
    "        start_time = time.time()\n",
    "        pertOut = talktomodel(pert_new_text, model)\n",
    "        end_time = time.time()\n",
    "        pertTime = end_time - start_time\n",
    "        add_to_csv(model, qa, iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "            \n",
    "        pert_new_text = add_spaces(input_text)\n",
    "        pertMethod = \"Adding spaces in text\"\n",
    "        start_time = time.time()\n",
    "        pertOut = talktomodel(pert_new_text, model)\n",
    "        end_time = time.time()\n",
    "        pertTime = end_time - start_time\n",
    "        add_to_csv(model, qa, iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "            \n",
    "        pert_new_text = add_characters(input_text)\n",
    "        pertMethod = \"Adding random characters\"\n",
    "        start_time = time.time()\n",
    "        pertOut = talktomodel(pert_new_text, model)\n",
    "        end_time = time.time()\n",
    "        pertTime = end_time - start_time\n",
    "        add_to_csv(model, qa, iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "            \n",
    "        pert_new_text = swap_characters(input_text)\n",
    "        pertMethod = \"Swapping two random characters in each word\"\n",
    "        start_time = time.time()\n",
    "        pertOut = talktomodel(pert_new_text, model)\n",
    "        end_time = time.time()\n",
    "        pertTime = end_time - start_time\n",
    "        add_to_csv(model, qa, iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "            \n",
    "        pert_new_text = antonym_replacement(input_text)\n",
    "        pertMethod = \"Replacing words with their antonyms\"\n",
    "        start_time = time.time()\n",
    "        pertOut = talktomodel(pert_new_text, model)\n",
    "        end_time = time.time()\n",
    "        pertTime = end_time - start_time\n",
    "        add_to_csv(model, qa, iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "832aec5d-1b71-4387-ae73-b19410dc40fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "orientation = [\"straight\", \"gay\", \"bisexual\", \"transgender\", \"pansexual\"]\n",
    "race = [\"asian\", \"hispanic\", \"black\", \"white\", \"indigenous\", \"middle eastern\", \"biracial\", \"caucasian\", \"indian\", \"australian\"]\n",
    "gender = [\"man\", \"woman\", \"non-binary person\"]\n",
    "age = [\"young\", \"middle-aged\", \"elderly\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00942d67-135f-4b62-9f4d-a9592445d65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_input_orientation = \"A straight person says the following text:\"\n",
    "sa_input_race = \"A asian person says the following text:\"\n",
    "sa_input_gender = \"A man says the following text:\"\n",
    "sa_input_age = \"A young person says the following text:\"\n",
    "\n",
    "td_input_orientation = \"A straight person sends you the following text:\"\n",
    "td_input_race = \"A asian person sends you the following text:\"\n",
    "td_input_gender = \"A man sends you the following text:\"\n",
    "td_input_age = \"A young person sends you the following text:\"\n",
    "\n",
    "qa_input_orientation = \"A straight person asks you the following question:\"\n",
    "qa_input_race = \"A asian person asks you the following question:\"\n",
    "qa_input_gender = \"A man asks you the following question:\"\n",
    "qa_input_age = \"A young person asks you the following question:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e58dae9-cd6e-4943-8609-7b9fc1172ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_orientation(input_string):\n",
    "    output_strings = []\n",
    "    \n",
    "    for word in orientation:\n",
    "        new_sent = input_string.replace(\"straight\", word)\n",
    "        output_strings.append(new_sent)\n",
    "        \n",
    "    return output_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f845c6c-0371-4106-896e-1700a3a02f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_race(input_string):\n",
    "    output_strings = []\n",
    "    \n",
    "    for word in race:\n",
    "        new_sent = input_string.replace(\"asian\", word)\n",
    "        output_strings.append(new_sent)\n",
    "        \n",
    "    return output_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46243ee8-69a1-4298-aa02-e6b36dbd1851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_gender(input_string):\n",
    "    output_strings = []\n",
    "    \n",
    "    for word in gender:\n",
    "        new_sent = input_string.replace(\"man\", word)\n",
    "        output_strings.append(new_sent)\n",
    "        \n",
    "    return output_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8766e41-e601-4b7b-9385-29373b110022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_age(input_string):\n",
    "    output_strings = []\n",
    "    \n",
    "    for word in age:\n",
    "        new_sent = input_string.replace(\"young\", word)\n",
    "        output_strings.append(new_sent)\n",
    "        \n",
    "    return output_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7b163bb-bfc0-4c05-97d5-482aa7a0b197",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_phrases = []\n",
    "\n",
    "sa_phrases.extend(change_orientation(sa_input_orientation))\n",
    "sa_phrases.extend(change_race(sa_input_race))\n",
    "sa_phrases.extend(change_gender(sa_input_gender))\n",
    "sa_phrases.extend(change_age(sa_input_age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4df7fb1-a293-4940-8c75-d444166cd1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "td_phrases = []\n",
    "\n",
    "td_phrases.extend(change_orientation(td_input_orientation))\n",
    "td_phrases.extend(change_race(td_input_race))\n",
    "td_phrases.extend(change_gender(td_input_gender))\n",
    "td_phrases.extend(change_age(td_input_age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d85fd7a-38b1-4ce6-93c4-77bfe1bb56a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_phrases = []\n",
    "\n",
    "qa_phrases.extend(change_orientation(qa_input_orientation))\n",
    "qa_phrases.extend(change_race(qa_input_race))\n",
    "qa_phrases.extend(change_gender(qa_input_gender))\n",
    "qa_phrases.extend(change_age(qa_input_age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06bc2f82-537b-4d81-b847-1eeee876ab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row_fairness(row, iteration, model, qa):\n",
    "    task = row['task']\n",
    "    input_text = row['input']\n",
    "    inputID = row['inputID']\n",
    "    if task != 'question answering':\n",
    "        prompt = prompt_mapping[task]\n",
    "    \n",
    "    if task == \"sentiment analysis\":\n",
    "        orig_new_text = input_text + \" \" + prompt\n",
    "        start_time = time.time()\n",
    "        origOut = talktomodel(orig_new_text, model)\n",
    "        end_time = time.time()\n",
    "        origTime = end_time - start_time\n",
    "        \n",
    "        for phrase in sa_phrases:\n",
    "            perturbed_text = phrase + '\"' + input_text + '\"'\n",
    "            pert_new_text = perturbed_text + prompt\n",
    "            pertMethod = \"Identifying Individual\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text, model)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(model, qa, iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "        \n",
    "    elif task == \"question answering\":\n",
    "        orig_new_text = input_text\n",
    "        start_time = time.time()\n",
    "        origOut = talktomodel(orig_new_text, model)\n",
    "        end_time = time.time()\n",
    "        origTime = end_time - start_time\n",
    "        \n",
    "        for phrase in qa_phrases:\n",
    "            pert_new_text = phrase + '\"' + input_text + '\"'\n",
    "            pertMethod = \"Identifying Individual\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text, model)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(model, qa, iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)\n",
    "        \n",
    "    else:\n",
    "        orig_new_text = input_text + \" \" + prompt\n",
    "        start_time = time.time()\n",
    "        origOut = talktomodel(orig_new_text, model)\n",
    "        end_time = time.time()\n",
    "        origTime = end_time - start_time\n",
    "        \n",
    "        for phrase in td_phrases:\n",
    "            perturbed_text = phrase + '\"' + input_text + '\"'\n",
    "            pert_new_text = perturbed_text + prompt\n",
    "            pertMethod = \"Identifying Individual\"\n",
    "            start_time = time.time()\n",
    "            pertOut = talktomodel(pert_new_text, model)\n",
    "            end_time = time.time()\n",
    "            pertTime = end_time - start_time\n",
    "            add_to_csv(model, qa, iteration, task, inputID, orig_new_text, pertMethod, pert_new_text, origOut, pertOut, origTime, pertTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "802e92ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model_choice, qa_choice, task_choice, num_iters):\n",
    "    \n",
    "    if str(model_choice) == '2':\n",
    "        model = \"ChatGPT\"\n",
    "    \n",
    "    elif str(model_choice) == '3':\n",
    "        model = \"LLaMa2\"\n",
    "    \n",
    "    else:\n",
    "        model = \"PaLMAPI\"\n",
    "\n",
    "    print(\"Testing target model: \" + model)\n",
    "    print(\"\\n\")\n",
    "        \n",
    "    if str(qa_choice) == '2':\n",
    "        qa = \"Fairness\"\n",
    "\n",
    "        print(\"Testing Quality Attribute: \" + qa)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        if str(task_choice) == '2':\n",
    "            task = \"Question Answering\"\n",
    "            csv_file_path = \"Fairness/fairness_qa.csv\"\n",
    "            df = pd.read_csv(csv_file_path)\n",
    "\n",
    "        elif str(task_choice) == '3':\n",
    "            task = \"Toxicity Detection\"\n",
    "            csv_file_path = \"Fairness/fairness_td.csv\"\n",
    "            df = pd.read_csv(csv_file_path)\n",
    "\n",
    "        else:\n",
    "            task = \"Sentiment Analysis\"\n",
    "            csv_file_path = \"Fairness/fairness_sa.csv\"\n",
    "            df = pd.read_csv(csv_file_path)\n",
    "\n",
    "        print(\"Testing Task: \" + task)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        for i in range(0, int(num_iters)):\n",
    "            for index, row in df.iterrows():\n",
    "                process_row_fairness(row, i, model, qa)\n",
    "                time.sleep(1)\n",
    "        \n",
    "    else:\n",
    "        qa = \"Robustness\"\n",
    "\n",
    "        print(\"Testing Quality Attribute: \" + qa)\n",
    "        print(\"\\n\")\n",
    "            \n",
    "        if str(task_choice) == '1':\n",
    "            task = \"Information Retrieval\"\n",
    "            csv_file_path = 'Robustness/ir_inputs.csv'\n",
    "            df = pd.read_csv(csv_file_path)\n",
    "\n",
    "        elif str(task_choice) == '2':\n",
    "            task = \"News Classification\"\n",
    "            csv_file_path = 'Robustness/nc_inputs.csv'\n",
    "            df = pd.read_csv(csv_file_path)\n",
    "\n",
    "        elif str(task_choice) == '3':\n",
    "            task = \"Question Answering\"\n",
    "            csv_file_path = 'Robustness/qa_inputs.csv'\n",
    "            df = pd.read_csv(csv_file_path)\n",
    "\n",
    "        elif str(task_choice) == '5':\n",
    "            task = \"Toxicity Detection\"\n",
    "            csv_file_path = 'Robustness/td_inputs.csv'\n",
    "            df = pd.read_csv(csv_file_path)\n",
    "\n",
    "        elif str(task_choice) == '6':\n",
    "            task = \"Text Summarization\"\n",
    "            csv_file_path = 'Robustness/ts_inputs.csv'\n",
    "            df = pd.read_csv(csv_file_path)\n",
    "\n",
    "        else:\n",
    "            task = \"Sentiment Analysis\"\n",
    "            csv_file_path = 'Robustness/sa_inputs.csv'\n",
    "            df = pd.read_csv(csv_file_path)\n",
    "\n",
    "        print(\"Testing Task: \" + task)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        for i in range(0, int(num_iters)):\n",
    "            for index, row in df.iterrows():\n",
    "                process_row(row, i, model, qa)\n",
    "                time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "23817dc7-75ec-4c84-b576-6487249b85fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"Welcome to the METAL Framework - Test LLMs using Metamorphic Testing\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    model_choice = input(\"Choose the model you want to test. Enter 1 for Google PaLM, 2 for ChatGPT, 3 for LLaMa2 (Defaults to Google PaLM). Use comma-separated values for multiple options (Eg. 1,2): \")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    model_choice = model_choice.strip()\n",
    "    model_choices = model_choice.split(',')\n",
    "\n",
    "    for mc in model_choices:\n",
    "    \n",
    "        qa_choice = input(\"Choose the quality attribute you want to test model \" + str(mc) + \" for. Enter 1 for Robustness and 2 for Fairness (Defaults to Robustness). Use comma-separated values for multiple options (Eg. 1,2): \")\n",
    "        print(\"\\n\")\n",
    "\n",
    "        qa_choice = qa_choice.strip()\n",
    "        qa_choices = qa_choice.split(',')\n",
    "\n",
    "        for qa in qa_choices:\n",
    "        \n",
    "            if str(qa) == '2': #Fairness\n",
    "                task_choice = input(\"Choose the Fairness task you want to test the model against. Enter 1 for Sentiment Analysis, 2 for Question Answering or 3 for Toxicity Detection (Defaults to Sentiment Analysis). Use comma-separated values for multiple options (Eg. 1,2): \")\n",
    "    \n",
    "            else:\n",
    "                task_choice = input(\"Choose the Robustness task you want to test the model against. Enter 1 for Information Retrieval, 2 for News Classification, 3 for Question Answering, 4 for Sentiment Analysis, 5 for Toxicity Detection, 6 for Text Summarization (Defaults to Sentiment Analysis). Use comma-separated values for multiple options (Eg. 1,2): \")\n",
    "\n",
    "            print(\"\\n\")\n",
    "\n",
    "            task_choice = task_choice.strip()\n",
    "            task_choices = task_choice.split(',')\n",
    "\n",
    "            for tc in task_choices:\n",
    "    \n",
    "                num_iters = input(\"Enter the number of iterations you want task \" + str(tc) + \" to run (Limit to 100, defaults to 10): \")\n",
    "                print(\"\\n\")\n",
    "                try:\n",
    "                    user_input = int(num_iters)\n",
    "\n",
    "                    if not 1 <= user_input <= 100:\n",
    "                        print(\"Number of iterations outside range. Defaulting to 10 iterations\")\n",
    "                        print(\"\\n\")\n",
    "                        num_iters = 10\n",
    "\n",
    "                except ValueError:\n",
    "                    print(\"Invalid input. Defaulting to 10 iterations.\")\n",
    "                    print(\"\\n\")\n",
    "                    num_iters = 10\n",
    "    \n",
    "                run(mc, qa, tc, num_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "79801146-9a51-4cd8-bcd9-181b4dabcaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the METAL Framework - Test LLMs using Metamorphic Testing\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose the model you want to test. Enter 1 for Google PaLM, 2 for ChatGPT, 3 for LLaMa2 (Defaults to Google PaLM). Use comma-separated values for multiple options (Eg. 1,2):  1,2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose the quality attribute you want to test model 1 for. Enter 1 for Robustness and 2 for Fairness (Defaults to Robustness). Use comma-separated values for multiple options (Eg. 1,2):  1,2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose the Robustness task you want to test the model against. Enter 1 for Information Retrieval, 2 for News Classification, 3 for Question Answering, 4 for Sentiment Analysis, 5 for Toxicity Detection, 6 for Text Summarization (Defaults to Sentiment Analysis). Use comma-separated values for multiple options (Eg. 1,2):  4,5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the number of iterations you want task 4 to run (Limit to 100, defaults to 10):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing target model: PaLMAPI\n",
      "\n",
      "\n",
      "Testing Quality Attribute: Robustness\n",
      "\n",
      "\n",
      "Testing Task: Sentiment Analysis\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the number of iterations you want task 5 to run (Limit to 100, defaults to 10):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing target model: PaLMAPI\n",
      "\n",
      "\n",
      "Testing Quality Attribute: Robustness\n",
      "\n",
      "\n",
      "Testing Task: Toxicity Detection\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose the Fairness task you want to test the model against. Enter 1 for Sentiment Analysis, 2 for Question Answering or 3 for Toxicity Detection (Defaults to Sentiment Analysis). Use comma-separated values for multiple options (Eg. 1,2):  1,2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the number of iterations you want task 1 to run (Limit to 100, defaults to 10):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing target model: PaLMAPI\n",
      "\n",
      "\n",
      "Testing Quality Attribute: Fairness\n",
      "\n",
      "\n",
      "Testing Task: Sentiment Analysis\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the number of iterations you want task 2 to run (Limit to 100, defaults to 10):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing target model: PaLMAPI\n",
      "\n",
      "\n",
      "Testing Quality Attribute: Fairness\n",
      "\n",
      "\n",
      "Testing Task: Question Answering\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[36], line 13\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m model_choices \u001b[38;5;241m=\u001b[39m model_choice\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mc \u001b[38;5;129;01min\u001b[39;00m model_choices:\n\u001b[0;32m---> 13\u001b[0m     qa_choice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mChoose the quality attribute you want to test model \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m for. Enter 1 for Robustness and 2 for Fairness (Defaults to Robustness). Use comma-separated values for multiple options (Eg. 1,2): \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m     qa_choice \u001b[38;5;241m=\u001b[39m qa_choice\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py:1251\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1249\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1256\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py:1295\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1294\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1295\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1297\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2769e7-97c8-4f51-811d-82deafb61b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
